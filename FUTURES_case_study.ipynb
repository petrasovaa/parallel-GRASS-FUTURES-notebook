{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Urban growth modeling in GRASS GIS: Parallel computing case study\n",
    "The purpose of this notebook is to demonstrate several parallel computing pronciples and how they are implemented in GRASS GIS.\n",
    "We use FUTURES urban growth model implemented as a GRASS GIS addon.\n",
    "\n",
    "This notebook requires prepared dataset available here. This dataset is a GRASS GIS Location containing:\n",
    " * NLCD 2001-2019\n",
    " * US county boundaries\n",
    " * US-PAD protected areas\n",
    " * USGS DEM\n",
    "\n",
    "The required software includes\n",
    " * _GRASS GIS v8.2_ with the following addons: _r.futures, r.mapcalc.tiled, r.sample.category_\n",
    " * _R_ with the following packages: _lme4, optparse, MuMIn, snow_\n",
    " * _GNU Parallel_\n",
    "\n",
    "The expected computing resources for the notebook as intended are 12 cores and 32GB memory. You can change those values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = 12\n",
    "memory = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines Python 3 and Bash cells. By default a code cell is in Python. We use IPython [cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics) including `%%bash`, `%%time`, and `%%writefile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "Change the current directory to wherever you unzipped the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/data/FUTURES/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python packages and initialize GRASS GIS session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "\n",
    "# Ask GRASS GIS where its Python packages are.\n",
    "sys.path.append(\n",
    "    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n",
    ")\n",
    "\n",
    "# Import GRASS packages\n",
    "import grass.script as gs\n",
    "import grass.jupyter as gj\n",
    "\n",
    "# Start GRASS Session\n",
    "session = gj.init(\".\", \"FUTURES\", \"PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install GRASS addons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.extension\", extension=\"r.futures\")\n",
    "gs.run_command(\"g.extension\", extension=\"r.mapcalc.tiled\")\n",
    "gs.run_command(\"g.extension\", extension=\"r.sample.category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List dataset layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g.list type=raster,vector -p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process county boundaries\n",
    "Extract states in South-East US (Alabama, Florida, Georgia, North carolina, South Carolina, Tennessee)\n",
    "and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "v.extract tl_2021_us_county output=SE_counties where=\"STATEFP in ('01', '12', '13', '37', '45', '47')\" --q\n",
    "v.db.addcolumn SE_counties column=\"state integer\" --q\n",
    "v.db.addcolumn SE_counties column=\"county integer\" --q\n",
    "v.db.update SE_counties col=state qcol=\"CAST(STATEFP AS integer)\" --q\n",
    "v.db.update SE_counties col=county qcol=\"CAST(GEOID AS integer)\" --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_vect(map=\"SE_counties\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and rasterize states for further parallelization steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [1, 12, 13, 37, 45, 47]\n",
    "gs.use_temp_region()\n",
    "for state in states:\n",
    "    gs.run_command(\"v.extract\", input=\"SE_counties\", where=f\"state == '{state}'\", output=f\"state_{state}\")\n",
    "    gs.run_command(\"g.region\", vector=f\"state_{state}\", align=\"nlcd_2019\")\n",
    "    gs.run_command(\"v.to.rast\", input=f\"state_{state}\", output=f\"state_{state}\", use=\"attr\", attribute_column=\"county\")\n",
    "gs.del_temp_region()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM to slope\n",
    "Compute slope with r.slope.aspect which uses OpenMP for parallelization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.slope.aspect\", elevation=\"DEM\", slope=\"slope\", flags=\"e\", nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"slope\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected land\n",
    "Rasterize protected areas to later include them in a mask. We use GridModule to split the computation in tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from grass.pygrass.modules.grid import GridModule\n",
    "\n",
    "grid = GridModule(\"v.to.rast\", input=\"protected\", output=\"protected\", type=\"area\", use=\"val\",\n",
    "                  processes=nprocs, patch_backend=\"r.patch\")\n",
    "grid.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"protected\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process NLCD data\n",
    "Most of our predictors we will derive from NLCD data (land cover type and impervious descriptor products). With r.reclass we create water, forest, roads, urban rasters.\n",
    "Note that those rasters are virtual (they behave the same way, but are only pointing to the original NLCD raster),\n",
    "so reclassification is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD_years = [2001, 2004, 2006, 2008, 2011, 2013, 2016, 2019]\n",
    "NLCD_descriptor_years = [2001, 2019]\n",
    "gs.write_command(\"r.reclass\", input=\"nlcd_2019\", output=\"water\", rules=\"-\", stdin=\"11 = 1\")\n",
    "gs.write_command(\"r.reclass\", input=\"nlcd_2019\", output=\"forest\", rules=\"-\", stdin=\"41 42 43 = 1\")\n",
    "gs.write_command(\"r.reclass\", input=\"nlcd_descriptor_2019\", output=\"roads\", rules=\"-\", stdin=\"20 21 22 23 = 1\")\n",
    "for year in NLCD_years:\n",
    "    gs.write_command(\"r.reclass\", input=f\"nlcd_{year}\", output=f\"urban_{year}\", rules=\"-\", stdin=\"21 22 23 24 = 1\\n* = 0\")\n",
    "for year in NLCD_descriptor_years:\n",
    "    gs.write_command(\"r.reclass\", input=f\"nlcd_descriptor_{year}\", output=f\"urban_no_roads_{year}\", rules=\"-\", stdin=\"24 25 26 = 1\\n* = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Bash use background processing (append &) to compute distance to water, forest, and roads in parallel since these are independent computations. Command wait forces to wait for the background processes to finish.\n",
    "Once the distance is computed, we use raster algebra to transform it logarithmically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "r.grow.distance input=water distance=dist_to_water -m &\n",
    "r.grow.distance input=forest distance=dist_to_forest -m &\n",
    "r.grow.distance input=roads distance=dist_to_roads -m &\n",
    "wait\n",
    "r.mapcalc \"log_dist_to_water = log(dist_to_water + 1)\" &\n",
    "r.mapcalc \"log_dist_to_forest = log(dist_to_forest + 1)\" &\n",
    "r.mapcalc \"log_dist_to_roads = log(dist_to_roads + 1)\" &\n",
    "wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"log_dist_to_forest\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUTURES uses a special predictor called development pressure, which can be computed with r.futures.devpressure, which is internally parallelized.\n",
    "Since we need to compute it for 2 years, we use a hybrid approach which runs both command as background process and each of them runs in parallel.\n",
    "To do that we split the number of available processes so that each r.futures.devpressure process gets half of the available processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{int(nprocs/2)}\"\n",
    "r.futures.devpressure input=urban_no_roads_2001 output=devpressure_2001 size=20 gamma=1 nprocs=$1 &\n",
    "r.futures.devpressure input=urban_no_roads_2019 output=devpressure_2019 size=20 gamma=1 nprocs=$1 &\n",
    "wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"devpressure_2001\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask\n",
    "Compute mask to avoid urban growth simulation in water, protected areas, and outside the study area. We use r.mapcalc.tiled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mapcalc.tiled\", expression=\"masking = if((isnull(protected) &&  isnull(water) && nlcd_2019), 1, null())\", nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"masking\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demand computation\n",
    "Here we compute how much land will be developed in each step of the simulation.\n",
    "Logarithmic curves are fit to per-capita land consumption data derived from NLCD time series and observed population for each county.\n",
    "\n",
    "This computation is parallelized by state. First we create a Python script that takes the state as an input parameter,\n",
    "sets the computational region to the state extent, excludes roads from the computation, and runs r.futures.demand,\n",
    "creating an output CSV and a plot specific to that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demand_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "# input parameter: state FIPS code\n",
    "state = sys.argv[1]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.mapcalc(\"MASK = if (isnull(roads), 1, null())\")\n",
    "gs.run_command(\"r.futures.demand\", subregions=f\"state_{state}\",\n",
    "               development=[f\"urban_{year}\" for year in [2001, 2004, 2006, 2008, 2011, 2013, 2016, 2019]],\n",
    "               observed_population=\"observed_population_SE_counties_NLCD_2001-2019.csv\",\n",
    "               projected_population=\"Hauer_2020_2100_SE_counties_SSP2_projections_demand.csv\",\n",
    "               simulation_times=list(range(2019, 2101)), method=\"logarithmic\",\n",
    "               demand=f\"demand_{state}.csv\", plot=f\"demand_{state}.png\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each state generate grass command calling the script within a temporary mapset and append the the line to a file `demand_jobs.sh`.\n",
    "Run these commands in parallel with GNU Parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{nprocs}\"\n",
    "rm -f demand_jobs.sh\n",
    "for S in 1 12 13 37 45 47\n",
    "do\n",
    "    echo grass --tmp-mapset FUTURES --exec python demand_for_state.py ${S} >> demand_jobs.sh\n",
    "done\n",
    "cat demand_jobs.sh\n",
    "parallel -j ${1} < demand_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results for one state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"demand_37.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Potential\n",
    "### Predictor Sampling\n",
    "First we need a layer representing newly developed areas between 2001 and 2019 (value 1) and areas that didn't transition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mapcalc.tiled\", expression=\"urban_change = if(urban_2001 == 0, if(urban_2019 == 1, 1, 0), null())\", nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to Demand computation, we create a script that is then executed with different states.\n",
    "Since we need to patch the results together, we won't use temporary mapset.\n",
    "Setting the mask ensures area outiside of it won't be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sampling_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "state = sys.argv[1]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.run_command(\"r.mask\", raster=f\"state_{state}\")\n",
    "# create an identical, virtual map of counties with different name to later simplify patching of attribute tables\n",
    "gs.write_command(\"r.reclass\", input=f\"state_{state}\", output=\"counties\", rules=\"-\", stdin=\"* = *\")\n",
    "gs.run_command(\"r.sample.category\", input=\"urban_change\", output=f\"sample_{state}\",\n",
    "               sampled=[\"counties\", \"slope\", \"devpressure_2001\", \"log_dist_to_forest\", \"log_dist_to_water\", \"log_dist_to_roads\"],\n",
    "               npoints=[10000, 5000],\n",
    "               random_seed=1)\n",
    "gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{nprocs}\"\n",
    "rm -f sampling_jobs.sh\n",
    "for S in 1 12 13 37 45 47\n",
    "do\n",
    "    # remove mapset to start fresh after previous run\n",
    "    rm -rf FUTURES/sampling_${S}\n",
    "    echo grass -c FUTURES/sampling_${S} --exec python sampling_for_state.py ${S} >> sampling_jobs.sh\n",
    "done\n",
    "parallel -j ${1} < sampling_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we patch the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"v.patch\", input=[f\"sample_{state}@sampling_{state}\" for state in states], output=\"samples\", flags=\"e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in to see samples in newly developed and undeveloped areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.region\", n=1496445, s=1473765, e=1373865, w=1346175, save=\"zoomin\")\n",
    "m = gj.GrassRenderer(use_region=\"zoomin\")\n",
    "m.d_rast(map=\"urban_change\")\n",
    "m.d_vect(map=\"samples_test\", size=10, fill_color=\"red\", icon=\"basic/pin\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential\n",
    "Runs r.futures.potential to select the \"best\" model and compute regression coefficients.\n",
    "The best model selection runs in parallel (parallelized in R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.futures.potential\", input=\"samples\", output=\"best_model.csv\",\n",
    "               columns=[\"slope\", \"devpressure_2001\", \"log_dist_to_forest\", \"log_dist_to_water\", \"log_dist_to_roads\"],\n",
    "               developed_column=\"urban_change\",\n",
    "               subregions_column=\"counties\",\n",
    "               random_column=\"devpressure_2001\",\n",
    "               min_variables=3,\n",
    "               nprocs=nprocs, flags=\"d\",\n",
    "               dredge_output=\"all_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"all_models.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"best_model.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "Here we derive the distribution of the historical patch sizes per county. r.futures.calib is internally parallelized,\n",
    "so depending on the number of available cores, you can select 1 or more cores for each r.futures.calib run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile calibration_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "state = sys.argv[1]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.run_command(\"r.futures.calib\", flags=\"sl\",\n",
    "               development_start=\"urban_2001\", development_end=\"urban_2019\",\n",
    "               subregions=f\"state_{state}\", patch_threshold=1800,\n",
    "               patch_sizes=f\"patch_sizes_{state}.csv\", nprocs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{int(nprocs/2)}\"\n",
    "rm -f calibration_jobs.sh\n",
    "for S in 1 12 13 37 45 47\n",
    "do\n",
    "    echo grass --tmp-mapset FUTURES/ --exec python calibration_for_state.py ${S} >> calibration_jobs.sh\n",
    "done\n",
    "parallel -j ${1} < calibration_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Growing Algorithm\n",
    "Putting all the intermediate results together, we can now finally run the simulation from 2019 until 2050.\n",
    "\n",
    "We restrict the memory consumption to 10 GB and we will run 3 simulations in parallel. r.futures.pga\n",
    "will be executed many times (number of stochastic runs * number of states = 10 * 6 = 60).\n",
    "If more memory is available, more cores can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simulation_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "state, seed = sys.argv[1:3]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.run_command(\"r.mask\", raster=\"masking\")\n",
    "gs.run_command(\"r.futures.pga\", developed=\"urban_2019\", development_pressure=\"devpressure_2019\",\n",
    "               compactness_mean=0.3, compactness_range=0.1, discount_factor=0.5,\n",
    "               predictors=[\"log_dist_to_forest\", \"log_dist_to_roads\", \"log_dist_to_water\", \"slope\"],\n",
    "               n_dev_neighbourhood=20, devpot_params=\"best_model.csv\", num_neighbors=4, seed_search=\"probability\",\n",
    "               development_pressure_approach=\"gravity\", gamma=1, scaling_factor=1,\n",
    "               subregions=f\"state_{state}\", demand=f\"demand_{state}.csv\", num_steps=31,\n",
    "               output=f\"out_state_{state}_seed_{seed}\", patch_sizes=f\"patch_sizes_{state}.csv\", memory=10, random_seed=seed)\n",
    "gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f pga_jobs.sh\n",
    "for SEED in {1..10}\n",
    "do\n",
    "    for STATE in 1 12 13 37 45 47\n",
    "    do\n",
    "        rm -rf FUTURES/pga_${STATE}_${SEED}\n",
    "        echo grass -c FUTURES/pga_${STATE}_${SEED} --exec python simulation_for_state.py ${STATE} ${SEED} >> pga_jobs.sh\n",
    "    done\n",
    "done\n",
    "time parallel -j 3 < pga_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we patch the results together. Tool r.patch is internally parallelized, so we can use that extra speed up is we have available cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{int(nprocs/2)}\"\n",
    "rm -f patch_jobs.sh\n",
    "for SEED in {1..10}\n",
    "do\n",
    "    MAPS=$(grass --tmp-mapset FUTURES/ --exec \\\n",
    "           g.list type=raster pattern=\"out_state_*_seed_${SEED}\" mapset=\"*\" -m separator=comma)\n",
    "    rm -rf FUTURES/results_${SEED}\n",
    "    echo grass -c FUTURES/results_${SEED} --exec r.patch input=${MAPS} output=\"out_seed_${SEED}\" nprocs=2 >> patch_jobs.sh\n",
    "done\n",
    "parallel -j ${1} < patch_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"out_seed_1@results_1\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Development Probability\n",
    "By aggregating the stochastic runs we can compute the projected development probability. First we reclassify output\n",
    "to binary developed/undeveloped results. Then we run r.series in parallel to compute how many times a cell was developed\n",
    "and then divide that by number of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reclass.txt\n",
    "-1 0 = 0\n",
    "1 thru 100 = 1\n",
    "* = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1, 11):\n",
    "    gs.run_command(\"r.reclass\", input=f\"out_seed_{seed}@results_{seed}\", output=f\"out_seed_{seed}\", rules=\"reclass.txt\")\n",
    "gs.run_command(\"r.series\", input=[f\"out_seed_{seed}\" for seed in range(1, 11)], output=\"sum\", method=\"sum\", nprocs=nprocs)\n",
    "gs.run_command(\"r.mapcalc.tiled\", expression=\"probability = float(sum) / 10\", width=width, height=height, nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"probability\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest loss analysis\n",
    "Here we compute future forest loss due to development, demonstrating how to parallelize computations using Python multiprocessing.\n",
    "The goal is to compute forest loss for each of 30x30 km tiles in parallel across the landscape to capture large scale forest loss patterns.\n",
    "To do that we use `GRASS_REGION` environmental variable and set different region for each seed and tile combination.\n",
    "\n",
    "We will run this as a Python script (not directly from the cell) because Python multiprocessing sometimes doesn't work well within a Jupyter Notebook.\n",
    "Results that include tile coordinate, seed, and number of forest cells are written as JSON to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile forest_loss.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from math import ceil\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import grass.script as gs\n",
    "from grass.exceptions import CalledModuleError\n",
    "\n",
    "\n",
    "def forest_loss_stats(params):\n",
    "    \"\"\"Compute projected forest loss for selected area.\n",
    "    This function can be safely run in parallel.\"\"\"\n",
    "    seed, region = params\n",
    "    # create unique temporary map names\n",
    "    forest_loss = f\"forest_{seed}_{region['n']}_{region['e']}\"\n",
    "    # copy and modify environment to change region based on input\n",
    "    env = os.environ.copy()\n",
    "    env[\"GRASS_REGION\"] = gs.region_env(align=\"forest\", **region)\n",
    "    # pass the environment, so that the computations run with different region than the current one\n",
    "    # compute lost forest comparing to 2019\n",
    "    gs.mapcalc(f\"{forest} = if (forest && out_seed_1@results_1 >= 0, 1, 0)\", env=env, quiet=True)\n",
    "    # get number of cells for 0 (no change) and 1 (forest lost) category\n",
    "    results = dict(gs.parse_command('r.stats', input=forest_loss, flags='cn', parse=(gs.parse_key_val, {'sep': ' ', 'val_type': int}), env=env, quiet=True))\n",
    "    # add N, E as a center of the region, and add seed to results\n",
    "    results[\"n\"] = (region[\"n\"] + region[\"s\"]) / 2\n",
    "    results[\"e\"] = (region[\"e\"] + region[\"w\"]) / 2\n",
    "    results[\"seed\"] = seed\n",
    "    # remove temporary maps\n",
    "    gs.run_command(\"g.remove\", type=\"raster\", name=forest_loss, flags=\"f\", quiet=True)\n",
    "    # return dictionary with results\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nprocs = int(sys.argv[1])\n",
    "    current = gs.region()\n",
    "    regions = []\n",
    "    tile = 1000\n",
    "    # create a region where each cell is a 30x30 km tile\n",
    "    gs.run_command(\"g.region\", res=tile * current[\"nsres\"], flags=\"a\", save=\"tiles\")\n",
    "    env = os.environ.copy()\n",
    "    env[\"GRASS_REGION\"] = gs.region_env(region=\"tiles\")\n",
    "    grid_region = gs.region(env=env)\n",
    "    # save extents of each tile\n",
    "    for row in range(int(grid_region[\"rows\"])):\n",
    "        for col in range(int(grid_region[\"cols\"])):\n",
    "            s = float(grid_region[\"s\"]) + row * float(grid_region[\"nsres\"])\n",
    "            n = float(grid_region[\"s\"]) + (row + 1) * float(grid_region[\"nsres\"])\n",
    "            w = float(grid_region[\"w\"]) + col * float(grid_region[\"ewres\"])\n",
    "            e = float(grid_region[\"w\"]) + (col + 1) * float(grid_region[\"ewres\"])\n",
    "            regions.append(\n",
    "                {\n",
    "                    \"n\": n,\n",
    "                    \"s\": s,\n",
    "                    \"w\": w,\n",
    "                    \"e\": e,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    params = []\n",
    "    # collect parameters (for each seed and tile)\n",
    "    for seed in range(1, 11):\n",
    "        for region in regions:\n",
    "            params.append((seed, region))\n",
    "\n",
    "    # execute forest loss computation for each tile in parallel\n",
    "    with Pool(processes=nprocs) as pool:\n",
    "        results = pool.map_async(forest_loss_stats, params).get()\n",
    "        # write results as json to file\n",
    "        with open(\"forest_results.json\", \"w\") as f:\n",
    "            json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the file with number of processes as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run forest_loss.py {nprocs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results, process them with Pandas and write a raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"forest_results.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = df[df['1'].notna()].groupby([\"n\", \"e\"])[[\"1\"]].mean()\n",
    "df[\"km\"] = df[\"1\"] * 900 / 1000000\n",
    "\n",
    "csv = df.drop(columns=[\"1\"]).to_csv(index=True, header=False)\n",
    "env = os.environ.copy()\n",
    "env[\"GRASS_REGION\"] = gs.region_env(region=\"tiles\")\n",
    "gs.write_command(\"r.in.xyz\", stdin=csv, input=\"-\", x=2, y=1, output=\"forest_loss\", method=\"mean\", separator=\"comma\", env=env)\n",
    "gs.run_command(\"r.colors\", map=\"forest_loss\", color=\"forest_cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"forest_loss\")\n",
    "m.d_vect(map=\"SE_counties\", fill_color=\"none\", color=\"grey\")\n",
    "m.d_legend(raster=\"forest_loss\", title=\"Loss of forest [km sq]\")\n",
    "m.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
