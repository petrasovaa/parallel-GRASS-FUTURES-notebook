{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Urban growth modeling in GRASS GIS: Parallel computing case study\n",
    "The purpose of this notebook is to demonstrate several parallel computing pronciples and how they are implemented in GRASS GIS.\n",
    "We use FUTURES urban growth model implemented as a GRASS GIS addon.\n",
    "\n",
    "This notebook requires prepared dataset available here. This dataset is a GRASS GIS Location containing:\n",
    " * NLCD 2001-2019\n",
    " * US county boundaries\n",
    " * US-PAD protected areas\n",
    " * USGS DEM\n",
    "\n",
    "The required software includes\n",
    " * _GRASS GIS v8.2_ with the following addons: _r.futures, r.mapcalc.tiled, r.sample.category_\n",
    " * _R_ with the following packages: _lme4, optparse, MuMIn, snow_\n",
    " * _GNU Parallel_\n",
    "\n",
    "The expected computing resources for the notebook as intended are 8 cores and 32GB memory. You can change those values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = 8\n",
    "memory = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines Python 3 and Bash cells. By default a code cell is in Python. We use IPython [cell magick](https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics) including `%%bash`, `%%time`, and `%%writefile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "Change the current directory to wherever you unzipped the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/data/FUTURES/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python packages and initialize GRASS GIS session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import pathlib\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "\n",
    "# Ask GRASS GIS where its Python packages are.\n",
    "sys.path.append(\n",
    "    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n",
    ")\n",
    "\n",
    "# Import GRASS packages\n",
    "import grass.script as gs\n",
    "import grass.jupyter as gj\n",
    "\n",
    "# Start GRASS Session\n",
    "session = gj.init(\".\", \"FUTURES\", \"PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install GRASS addons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.extension\", extension=\"r.futures\")\n",
    "gs.run_command(\"g.extension\", extension=\"r.mapcalc.tiled\")\n",
    "gs.run_command(\"g.extension\", extension=\"r.sample.category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List dataset layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g.list type=raster,vector -p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process county boundaries\n",
    "Extract states in South-East US (Alabama, Florida, Georgia, North carolina, South Carolina, Tennessee)\n",
    "and convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "v.extract tl_2021_us_county output=SE_counties where=\"STATEFP in ('01', '12', '13', '37', '45', '47')\" --q\n",
    "v.db.addcolumn SE_counties column=\"state integer\" --q\n",
    "v.db.addcolumn SE_counties column=\"county integer\" --q\n",
    "v.db.update SE_counties col=state qcol=\"CAST(STATEFP AS integer)\" --q\n",
    "v.db.update SE_counties col=county qcol=\"CAST(GEOID AS integer)\" --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_vect(map=\"SE_counties\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split and rasterize states for further parallelization steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [1, 12, 13, 37, 45, 47]\n",
    "gs.use_temp_region()\n",
    "for state in states:\n",
    "    gs.run_command(\"v.extract\", input=\"SE_counties\", where=f\"state == '{state}'\", output=f\"state_{state}\")\n",
    "    gs.run_command(\"g.region\", vector=f\"state_{state}\", align=\"nlcd_2019\")\n",
    "    gs.run_command(\"v.to.rast\", input=f\"state_{state}\", output=f\"state_{state}\", use=\"attr\", attribute_column=\"county\")\n",
    "gs.del_temp_region()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEM to slope\n",
    "Compute slope with r.slope.aspect which uses OpenMP for parallelization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.slope.aspect\", elevation=\"DEM\", slope=\"slope\", flags=\"e\", nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"slope\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected land\n",
    "Rasterize protected areas to later include them in a mask. We use GridModule to split the computation in tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "from grass.pygrass.modules.grid import GridModule\n",
    "\n",
    "grid = GridModule(\"v.to.rast\", input=\"protected\", output=\"protected\", type=\"area\", use=\"val\",\n",
    "                  processes=nprocs, patch_backend=\"r.patch\")\n",
    "grid.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"protected\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process NLCD data\n",
    "Most of our predictors we will derive from NLCD data (land cover type and impervious descriptor products). With r.reclass we create water, forest, roads, urban rasters.\n",
    "Note that those rasters are virtual (they behave the same way, but are only pointing to the original NLCD raster),\n",
    "so reclassification is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD_years = [2001, 2004, 2006, 2008, 2011, 2013, 2016, 2019]\n",
    "NLCD_descriptor_years = [2001, 2019]\n",
    "gs.write_command(\"r.reclass\", input=\"nlcd_2019\", output=\"water\", rules=\"-\", stdin=\"11 = 1\")\n",
    "gs.write_command(\"r.reclass\", input=\"nlcd_2019\", output=\"forest\", rules=\"-\", stdin=\"41 42 43 = 1\")\n",
    "gs.write_command(\"r.reclass\", input=\"nlcd_descriptor_2019\", output=\"roads\", rules=\"-\", stdin=\"20 21 22 23 = 1\")\n",
    "for year in NLCD_years:\n",
    "    gs.write_command(\"r.reclass\", input=f\"nlcd_{year}\", output=f\"urban_{year}\", rules=\"-\", stdin=\"21 22 23 24 = 1\\n* = 0\")\n",
    "for year in NLCD_descriptor_years:\n",
    "    gs.write_command(\"r.reclass\", input=f\"nlcd_descriptor_{year}\", output=f\"urban_no_roads_{year}\", rules=\"-\", stdin=\"24 25 26 = 1\\n* = 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Bash use background processing (append &) to compute distance to water, forest, and roads in parallel since these are independent computations. Command wait forces to wait for the background processes to finish.\n",
    "Once the distance is computed, we use raster algebra to transform it logarithmically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "r.grow.distance input=water distance=dist_to_water -m &\n",
    "r.grow.distance input=forest distance=dist_to_forest -m &\n",
    "r.grow.distance input=roads distance=dist_to_roads -m &\n",
    "wait\n",
    "r.mapcalc \"log_dist_to_water = log(dist_to_water + 1)\" &\n",
    "r.mapcalc \"log_dist_to_forest = log(dist_to_forest + 1)\" &\n",
    "r.mapcalc \"log_dist_to_roads = log(dist_to_roads + 1)\" &\n",
    "wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"log_dist_to_forest\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUTURES uses a special predictor called development pressure, which can be computed with r.futures.devpressure, which is internally parallelized.\n",
    "Since we need to compute it for 2 years, we use a hybrid approach which runs both command as background process and each of them runs in parallel.\n",
    "To do that we split the number of available processes so that each r.futures.devpressure process gets half of the available processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{int(nprocs/2)}\"\n",
    "r.futures.devpressure input=urban_no_roads_2001 output=devpressure_2001 size=20 gamma=1 nprocs=$1 &\n",
    "r.futures.devpressure input=urban_no_roads_2019 output=devpressure_2019 size=20 gamma=1 nprocs=$1 &\n",
    "wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"devpressure_2001\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask\n",
    "Compute mask to avoid urban growth simulation in water, protected areas, and outside the study area. We use r.mapcalc.tiled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mapcalc.tiled\", expression=\"masking = if((isnull(protected) &&  isnull(water) && nlcd_2019), 1, null())\", nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"masking\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demand computation\n",
    "Here we compute how much land will be developed in each step of the simulation.\n",
    "Logarithmic curves are fit to per-capita land consumption data derived from NLCD time series and observed population for each county.\n",
    "\n",
    "This computation is parallelized by state. First we create a Python script that takes the state as an input parameter,\n",
    "sets the computational region to the state extent, excludes roads from the computation, and runs r.futures.demand,\n",
    "creating an output CSV and a plot specific to that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile demand_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "# input parameter: state FIPS code\n",
    "state = sys.argv[1]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.mapcalc(\"MASK = if (isnull(roads), 1, null())\")\n",
    "gs.run_command(\"r.futures.demand\", subregions=f\"state_{state}\",\n",
    "               development=[f\"urban_{year}\" for year in [2001, 2004, 2006, 2008, 2011, 2013, 2016, 2019]],\n",
    "               observed_population=\"observed_population_SE_counties_NLCD_2001-2019.csv\",\n",
    "               projected_population=\"Hauer_2020_2100_SE_counties_SSP2_projections_demand.csv\",\n",
    "               simulation_times=list(range(2019, 2101)), method=\"logarithmic\",\n",
    "               demand=f\"demand_{state}.csv\", plot=f\"demand_{state}.png\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each state generate grass command calling the script within a temporary mapset and append the the line to a file `demand_jobs.sh`.\n",
    "Run these commands in parallel with GNU Parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{nprocs}\"\n",
    "rm -f demand_jobs.sh\n",
    "for S in 1 12 13 37 45 47\n",
    "do\n",
    "    echo grass --tmp-mapset FUTURES --exec python demand_for_state.py ${S} >> demand_jobs.sh\n",
    "done\n",
    "cat demand_jobs.sh\n",
    "parallel -j ${1} < demand_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results for one state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"demand_37.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Potential\n",
    "### Predictor Sampling\n",
    "First we need a layer representing newly developed areas between 2001 and 2019 (value 1) and areas that didn't transition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.mapcalc.tiled\", expression=\"urban_change = if(urban_2001 == 0, if(urban_2019 == 1, 1, 0), null())\", nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to Demand computation, we create a script that is then executed with different states.\n",
    "Since we need to patch the results together, we won't use temporary mapset.\n",
    "Setting the mask ensures area outiside of it won't be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sampling_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "state = sys.argv[1]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.run_command(\"r.mask\", raster=f\"state_{state}\")\n",
    "# create an identical, virtual map of counties with different name to later simplify patching of attribute tables\n",
    "gs.write_command(\"r.reclass\", input=f\"state_{state}\", output=\"counties\", rules=\"-\", stdin=\"* = *\")\n",
    "gs.run_command(\"r.sample.category\", input=\"urban_change\", output=f\"sample_{state}\",\n",
    "               sampled=[\"counties\", \"slope\", \"devpressure_2001\", \"log_dist_to_forest\", \"log_dist_to_water\", \"log_dist_to_roads\"],\n",
    "               npoints=[10000, 5000],\n",
    "               random_seed=1)\n",
    "gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{nprocs}\"\n",
    "rm -f sampling_jobs.sh\n",
    "for S in 1 12 13 37 45 47\n",
    "do\n",
    "    # remove mapset to start fresh after previous run\n",
    "    rm -rf FUTURES/sampling_${S}\n",
    "    echo grass -c FUTURES/sampling_${S} --exec python sampling_for_state.py ${S} >> sampling_jobs.sh\n",
    "done\n",
    "parallel -j ${1} < sampling_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we patch the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"v.patch\", input=[f\"sample_{state}@sampling_{state}\" for state in states], output=\"samples\", flags=\"e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom in to see samples in newly developed and undeveloped areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"g.region\", n=1496445, s=1473765, e=1373865, w=1346175, save=\"zoomin\")\n",
    "m = gj.GrassRenderer(use_region=\"zoomin\")\n",
    "m.d_rast(map=\"urban_change\")\n",
    "m.d_vect(map=\"samples_test\", size=10, fill_color=\"red\", icon=\"basic/pin\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential\n",
    "Runs r.futures.potential to select the \"best\" model and compute regression coefficients.\n",
    "The best model selection runs in parallel (parallelized in R)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.run_command(\"r.futures.potential\", input=\"samples\", output=\"best_model.csv\",\n",
    "               columns=[\"slope\", \"devpressure_2001\", \"log_dist_to_forest\", \"log_dist_to_water\", \"log_dist_to_roads\"],\n",
    "               developed_column=\"urban_change\",\n",
    "               subregions_column=\"counties\",\n",
    "               random_column=\"devpressure_2001\",\n",
    "               min_variables=3,\n",
    "               nprocs=nprocs, flags=\"d\",\n",
    "               dredge_output=\"all_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"all_models.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"best_model.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "Here we derive the distribution of the historical patch sizes per county. r.futures.calib is internally parallelized, however\n",
    "with 8 cores, we can't use the internal parallelization because we are also parallelizing on the level of states.\n",
    "If you have more cores, use `nprocs=` with more cores than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile calibration_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "state = sys.argv[1]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.run_command(\"r.futures.calib\", flags=\"sl\",\n",
    "               development_start=\"urban_2001\", development_end=\"urban_2019\",\n",
    "               subregions=f\"state_{state}\", patch_threshold=1800,\n",
    "               patch_sizes=f\"patch_sizes_{state}.csv\", nprocs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{nprocs}\"\n",
    "rm -f calibration_jobs.sh\n",
    "for S in 1 12 13 37 45 47\n",
    "do\n",
    "    echo grass --tmp-mapset FUTURES/ --exec python calibration_for_state.py ${S} >> calibration_jobs.sh\n",
    "done\n",
    "parallel -j ${1} < calibration_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Growing Algorithm\n",
    "Putting all the intermediate results together, we can now finally run the simulation from 2019 until 2050.\n",
    "\n",
    "We restrict the memory consumption to 10 GB and we will run 3 simulations in parallel. r.futures.pga\n",
    "will be executed many times (number of stochastic runs * number of states = 10 * 6 = 60).\n",
    "If more memory is available, more cores can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simulation_for_state.py\n",
    "import sys\n",
    "import grass.script as gs\n",
    "\n",
    "state, seed = sys.argv[1:3]\n",
    "\n",
    "gs.run_command(\"g.region\", raster=f\"state_{state}\")\n",
    "gs.run_command(\"r.mask\", raster=\"masking\")\n",
    "gs.run_command(\"r.futures.pga\", developed=\"urban_2019\", development_pressure=\"devpressure_2019\",\n",
    "               compactness_mean=0.3, compactness_range=0.1, discount_factor=0.5,\n",
    "               predictors=[\"log_dist_to_forest\", \"log_dist_to_roads\", \"log_dist_to_water\", \"slope\"],\n",
    "               n_dev_neighbourhood=20, devpot_params=\"best_model.csv\", num_neighbors=4, seed_search=\"probability\",\n",
    "               development_pressure_approach=\"gravity\", gamma=1, scaling_factor=1,\n",
    "               subregions=f\"state_{state}\", demand=f\"demand_{state}.csv\", num_steps=31,\n",
    "               output=f\"out_state_{state}_seed_{seed}\", patch_sizes=f\"patch_sizes_{state}.csv\", memory=10, random_seed=seed)\n",
    "gs.run_command(\"r.mask\", flags=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f pga_jobs.sh\n",
    "for SEED in {1..10}\n",
    "do\n",
    "    for STATE in 1 12 13 37 45 47\n",
    "    do\n",
    "        rm -rf FUTURES/pga_${STATE}_${SEED}\n",
    "        echo grass -c FUTURES/pga_${STATE}_${SEED} --exec python simulation_for_state.py ${STATE} ${SEED} >> pga_jobs.sh\n",
    "    done\n",
    "done\n",
    "time parallel -j 3 < pga_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we patch the results together. Tool r.patch is internally parallelized, so we can use that extra speed up is we have available cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"{nprocs}\"\n",
    "rm -f patch_jobs.sh\n",
    "for SEED in {1..10}\n",
    "do\n",
    "    MAPS=$(grass --tmp-mapset FUTURES/ --exec \\\n",
    "           g.list type=raster pattern=\"out_state_*_seed_${SEED}\" mapset=\"*\" -m separator=comma)\n",
    "    rm -rf FUTURES/results_${SEED}\n",
    "    echo grass -c FUTURES/results_${SEED} --exec r.patch input=${MAPS} output=\"out_seed_${SEED}\" nprocs=1 >> patch_jobs.sh\n",
    "done\n",
    "parallel -j ${1} < patch_jobs.sh 2> log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"out_seed_1@results_1\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Development Probability\n",
    "By aggregating the stochastic runs we can compute the projected development probability. First we reclassify output\n",
    "to binary developed/undeveloped results. Then we run r.series in parallel to compute how many times a cell was developed\n",
    "and then divide that by number of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reclass.txt\n",
    "-1 0 = 0\n",
    "1 thru 100 = 1\n",
    "* = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(1, 11):\n",
    "    gs.run_command(\"r.reclass\", input=f\"out_seed_{seed}@results_{seed}\", output=f\"out_seed_{seed}\", rules=\"reclass.txt\")\n",
    "gs.run_command(\"r.series\", input=[f\"out_seed_{seed}\" for seed in range(1, 11)], output=\"sum\", method=\"sum\", nprocs=nprocs)\n",
    "gs.run_command(\"r.mapcalc.tiled\", expression=\"probability = float(sum) / 10\", width=width, height=height, nprocs=nprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gj.GrassRenderer()\n",
    "m.d_rast(map=\"probability\")\n",
    "m.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reclass.txt\n",
    "-1 = 0\n",
    "0 thru 100 = 1\n",
    "* = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.write_command(\"r.reclass\", input=f\"nlcd_2019\", output=\"urban_2019\", rules=\"-\", stdin=\"21 22 23 24 = 1\\n* = 0\")\n",
    "for seed in range(1, 11):\n",
    "    gs.run_command(\"r.reclass\", input=f\"out_seed_{seed}@results_{seed}\", output=f\"out_seed_{seed}\", rules=\"reclass.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def compute(params):\n",
    "    state, seed = params\n",
    "    env = os.environ.copy()\n",
    "    env[\"GRASS_REGION\"] = gs.region_env(raster=f\"state_{state}\")\n",
    "    results = gs.read_command(\n",
    "        \"r.futures.validation\", reference=\"urban_2019\", simulated=f\"out_seed_{seed}\", format=\"json\", env=env, quiet=True,\n",
    "    )\n",
    "    results = json.loads(results)\n",
    "    results[\"state\"] = state\n",
    "    return results\n",
    "\n",
    "params = []\n",
    "for seed in range(1, 11):\n",
    "    for state in states:\n",
    "        params.append((state, seed))\n",
    "\n",
    "with Pool(processes=nprocs) as pool:\n",
    "    results = pool.map_async(compute, params).get()\n",
    "\n",
    "pd.DataFrame(results).groupby(\"state\")[\"total_allocation\", \"total_quantity\", \"kappa\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"best_model.csv\", index_col=0)\n",
    "df.loc[37183]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest fragmentation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from multiprocessing import Pool\n",
    "from grass.exceptions import CalledModuleError\n",
    "\n",
    "\n",
    "def forest_fragmentation(seed):\n",
    "    forest = f'forest_2050_{seed}'\n",
    "    fragmentation = f'fragment_{seed}'\n",
    "    # forest in 2050\n",
    "    try:\n",
    "        gs.mapcalc(f\"{forest} = if(isnull(forest), 0, if(isnull(out_seed_{seed}), 1, if (out_seed_{seed} == -1, 1, 0)))\")\n",
    "        gs.run_command('r.forestfrag', flags='a', input=forest, output=fragmentation, window=25)\n",
    "        gs.run_command('g.remove', type='raster', name=[forest], flags='f')\n",
    "        return True\n",
    "    except CalledModuleError:\n",
    "        return False\n",
    "\n",
    "    \n",
    "with Pool(processes=nprocs) as pool:\n",
    "    success = pool.map_async(forest_fragmentation, list(range(1, 11))).get()\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragmentation_stats(params):\n",
    "    env = os.environ.copy()\n",
    "    seed, region = params\n",
    "    env[\"GRASS_REGION\"] = gs.region_env(**region)\n",
    "    results = gscript.parse_command('r.stats', input=f'fragment_{seed}', flags='cn', parse=(gs.parse_key_val, {'sep': ' ', 'val_type': int}), env=env)\n",
    "    results[\"n\"] = (region[\"n\"] + region[\"s\"]) / 2\n",
    "    results[\"e\"] = (region[\"e\"] + region[\"w\"]) / 2\n",
    "    results[\"seed\"] = seed\n",
    "    return \n",
    "\n",
    "\n",
    "region = gs.region()\n",
    "regions = []\n",
    "grid = 1000\n",
    "row = col = 0\n",
    "for row in range(ceil(region[\"rows\"] / grid) + 1):\n",
    "    for col in range(ceil(region[\"cols\"] / grid) + 1):\n",
    "        s = region[\"s\"] + row * grid * region[\"nsres\"]\n",
    "        n = region[\"s\"] + (row + 1) * grid * region[\"nsres\"]\n",
    "        w = region[\"w\"] + col * grid * region[\"ewres\"]\n",
    "        e = region[\"w\"] + (col + 1) * grid * region[\"ewres\"]\n",
    "        regions.append(\n",
    "            {\n",
    "                \"n\": n,\n",
    "                \"s\": s,\n",
    "                \"w\": w,\n",
    "                \"e\": e,\n",
    "                \"nsres\": region[\"nsres\"]),\n",
    "                \"ewres\": region[\"ewres\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "params = []\n",
    "for seed in range(1, 11):\n",
    "    for region in regions:\n",
    "        params.append((seed, region))\n",
    "\n",
    "with Pool(processes=nprocs) as pool:\n",
    "    results = pool.map_async(fragmentation_stats, params).get()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
